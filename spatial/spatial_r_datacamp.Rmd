---
title: "Spatial Analysis with sf and raster in R"
output: html_notebook
---

### Reading vector data
The sf package, created by Edzer Pebesma and colleagues, has dramatically simplified reading vector spatial data into R.

In this exercise you will read in three shapefiles (one point file and two polygon files) using st_read(). If you've read in the files correctly, you will see a standard R data frame except it will show some header metadata about the file and you'll see a special geometry column which we will discuss later.

```{r}
# Load the sf package
library(sf)

# Read in the trees shapefile
trees <- st_read("trees.shp")

# Read in the neighborhood shapefile
neighborhoods <- st_read("neighborhoods.shp")

# Read in the parks shapefile
parks <- st_read("parks.shp")

# View the first few trees
head(trees)
```

### Reading raster data
The term "raster" refers to gridded data that can include satellite imagery, aerial photographs (like orthophotos) and other types. In R, raster data can be handled using the raster package created by Robert J. Hijmans.

When working with raster data, one of the most important things to keep in mind is that the raw data can be what is known as "single-band" or "multi-band" and these are handled a little differently in R. Single-band rasters are the simplest, these have a single layer of raster values -- a classic example would be an elevation raster where each cell value represents the elevation at that location.

Multi-band rasters will have more than one layer. An example is a color aerial photo in which there would be one band each representing red, green or blue light.

```{r}
# Load the raster package
library(raster)

# Read in the tree canopy single-band raster
canopy <- raster('canopy.tif')

# Read in the manhattan Landsat image multi-band raster
manhattan <- brick("manhattan.tif")

# Get the class for the new objects
class(canopy)
class(manhattan)

# Identify how many layers each object has
nlayers(canopy)
nlayers(manhattan)
```

### sf objects are data frames
As mentioned in the video, spatial objects in sf are just data frames with some special properties. This means that packages like dplyr can be used to manipulate sf objects. In this exercise, you will use the dplyr functions select() to select or drop variables, filter() to filter the data and mutate() to add or alter columns.

We will also use the pipe operator (%>%) to save us some typing and simplify our code. If you're not familiar with the pipe, just think of it as the joints between an R workflow (pipeline) taking the result from the left hand side and sending it on to the next function. For example:

```{r}
1:10 %>% mean %>% log
```

will create a vector 1 to 10 and "pipe" it over to the mean() function, then it will pipe this result to the log() function (the result in this case is 1.704748).

To learn more you can check out the course Data Manipulation in R with dplyr.

```{r}
# Load the sf package
library(sf)

# ... and the dplyr package
library(dplyr)

# Read in the trees shapefile
trees <- st_read("trees.shp")

# Use filter() to limit to honey locust trees
honeylocust <- trees %>% filter(species == "honeylocust")

# Count the number of rows
nrow(honeylocust)

# Limit to tree_id and boroname variables
honeylocust_lim <- honeylocust %>% select(tree_id, boroname) 

# Use head() to look at the first few records
head(honeylocust_lim)
```

### Geometry is stored in list-columns
A major innovation in sf is that spatial objects are data frames. This is possible thanks, in part, to the list-column.

A list-column behaves, to a certain extent, like any other R column. The main difference is that instead of a standard value such as a single number, character or boolean value, each observation value in that column is a piece of an R list and this list can be as complex as needed. The list column allows you to store far more information in a single variable and sf takes advantage of this by storing all geographic information for each feature in the list.

In this exercise, you will convert the data frame to what's called a tibble with tibble::as_tibble() (Note that dplyr::tbl_df() is now deprecated).

```{r}
# Create a standard, non-spatial data frame with one column
df <- data.frame(a = 1:3)

# Add a list column to your data frame
df$b <- list(1:4, 1:5, 1:10)

# Look at your data frame with head
head(df)

# Convert your data frame to a tibble and print on console
as_tibble(df)

# Pull out the third observation from both columns individually
df$a[3]
df$b[3]
```

### Extracting geometric information from your vector layers
There are several functions in sf that allow you to access geometric information like area from your vector features. For example, the functions st_area() and st_length() return the area and length of your features, respectively.

Note that the result of functions like st_area() and st_length() will not be a traditional vector. Instead the result has a class of units which means the vector result is accompanied by metadata describing the object's units.

```{r}
# This will not work
result <- st_area(parks)
result > 30000

# Instead you need to either remove the units with unclass():

# This will work
val <- 30000
unclass(result) > val

# or you need to convert val's class to units, for example:
# This will work
units(val) <- units(result)
result > val

# Read in the parks shapefile
parks <- st_read("parks.shp")

# Compute the areas of the parks
areas <- st_area(parks)

# Create a quick histogram of the areas using hist
hist(areas, xlim = c(0, 200000), breaks = 1000)

# Filter to parks greater than 30000 (square meters)
big_parks <- parks %>% filter(unclass(areas) > 30000)

# Plot just the geometry of big_parks
plot(st_geometry(big_parks))
```

### First look at plotting vector spatial objects
The function for making a quick map/plot is a function you are already familiar with, plot(). You can, for example, type plot(my_data) to see your spatial object. The default, though, may not be what you want. The plot() function, when applied to sf objects, will create a set of maps, one for each attribute in your data. Instead, if you want to create a map of a single attribute you can extract that attribute using, as an example, plot(my_data["my_variable"]).

Frequently you just want to plot the raw geometry with no attribute color-coding (e.g., adding county boundaries to a map of points). For this, you can use the st_geometry() function to extract the geometry and plot the result. You can either create a new object or you can nest st_geometry() within the plot() function.

```{r}
# Plot the parks object using all defaults
plot(parks)

# Plot just the acres attribute of the parks data
plot(parks["acres"])

# Create a new object of just the parks geometry
parks_geo <- st_geometry(parks)

# Plot the geometry of the parks data
plot(parks_geo)
```

### Learning about your raster objects
Instead of storing raster objects in data frames, the raster package stores spatial data in specially designed R classes that contain slots where the data and metadata are stored. The data and metadata can be accessed using a suite of functions. For example, the spatial extent (the bounding box) of the object can be accessed with extent(), the coordinate reference system can be accessed with crs() and the number of grid cells can be determined with ncell().

```{r}
# Load the raster package
library(raster)

# Read in the rasters
canopy <- raster("canopy.tif")
manhattan <- brick("manhattan.tif")

# Get the extent of the canopy object
extent(canopy)

# Get the CRS of the manhattan object
crs(manhattan)

# Determine the number of grid cells in both raster objects
ncell(manhattan)
ncell(canopy)
```

### Accessing raster data values
Raster data can be very big depending on the extent and resolution (grid size). In order to deal with this the raster() and brick() functions are designed to only read in the actual raster values as needed. To show that this is true, you can use the inMemory() function on an object and it will return FALSE if the values are not in memory. If you use the head() function, the raster package will read in only the values needed, not the full set of values. The raster values will be read in by default if you perform spatial analysis operations that require it or you can read in the values from a raster manually with the function getValues().

```{r}
# Check if the data is in memory
inMemory(canopy)

# Use head() to peak at the first few records
head(canopy)

# Use getValues() to read the values into a vector
vals <- getValues(canopy)

# Use hist() to create a histogram of the values
hist(vals)
```

### Plot your raster object
Similar to what you saw in the exercises related to vector objects it's often useful to quickly look at a map of your raster objects with the plot() function.

The raster package has added useful methods for plotting both single and multi-band rasters. For single-band rasters or for a map of each layer in a multi-band raster you can simply use plot(). If you have a multi-band raster with layers for red, green and blue light you can use the plotRGB() function to plot the raster layers together as a single image.

```{r}
# Plot the canopy raster (single raster)
plot(canopy)

# Plot the manhattan raster (as a single image for each layer)
plot(manhattan)

# Plot the manhattan raster as an image
plotRGB(manhattan)
```

### Vector and raster coordinate systems
In order to perform any spatial analysis with more than one layer, your layers should share the same coordinate reference system (CRS) and the first step is determining what coordinate reference system your data has. To do this you can make use of the sf function st_crs() and the raster function crs().

When the geographic data you read in with sf already has a CRS defined both sf and raster will recognize and retain it. When the CRS is not defined you will need to define it yourself using either the EPSG number or the proj4string.

```{r}
# Determine the CRS for the neighborhoods and trees vector objects
st_crs(neighborhoods)
st_crs(trees)

# Assign the CRS to trees
crs_1 <- "+proj=longlat +ellps=WGS84 +no_defs"
st_crs(trees) <- crs_1

# Determine the CRS for the canopy and manhattan rasters
crs(canopy)
crs(manhattan)

# Assign the CRS to manhattan
crs_2 <- "+proj=utm +zone=18 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
crs(manhattan) <- crs_2
```

### Transform your layers to a common CRS
In the previous exercise, when you ran st_crs() and crs() you may have noticed that the CRS' were different for the different layers. The vector layer's CRS began with +proj=longlat and the raster layer's began with +proj=utm or +proj=aea. In order to use these layers together in spatial analysis we will want them to have the same CRS.

In this exercise you will transform (sometimes this is called "project") the objects so they share a single CRS. It is generally best to perform spatial analysis with layers that have a projected CRS (and some functions require this). To determine if your object has a projected CRS you can look at the first part of the result from st_crs() or crs() -- if it begins with +proj=longlat then your CRS is unprojected.

Note that you will use method = "ngb" in your call to projectRaster() to prevent distortion in the manhattan image.

```{r}
# Get the CRS from the canopy object
the_crs <- crs(canopy, asText = TRUE)

# Project trees to match the CRS of canopy
trees_crs <- st_transform(trees, crs = the_crs)

# Project neighborhoods to match the CRS of canopy
neighborhoods_crs <- st_transform(neighborhoods, crs = the_crs)

# Project manhattan to match the CRS of canopy
manhattan_crs <- projectRaster(manhattan, crs = the_crs, method = "ngb")

# Look at the CRS to see if they match
st_crs(trees_crs)
st_crs(neighborhoods_crs)
crs(manhattan_crs)
```

### Plot vector and raster together
If the layers do not share a common CRS they may not align on a plot. To illustrate, in this exercise, you will initially create a plot with the plot() function and try to add two layers that do not share the same CRS. You will then transform one layer's CRS to match the other and you will plot this with both the plot() function and functions from the tmap package.

Note that for this exercise we returned all the layers to their original CRS and did not retain the changes you made in the last exercise.

With the plot() function you can plot multiple layers on the same map by calling plot() multiple times. You'll need to add the argument add = TRUE to all calls to plot() after the first one and you need to run the code for all layers at once rather than line-by-line.

```{r}
# Plot canopy and neighborhoods (run both lines together)
# Do you see the neighborhoods?
plot(canopy)
plot(neighborhoods, add = TRUE)

# See if canopy and neighborhoods share a CRS
st_crs(neighborhoods)
crs(canopy)

# Save the CRS of the canopy layer
the_crs <- crs(canopy, asText = TRUE)

# Transform the neighborhoods CRS to match canopy
neighborhoods_crs <- st_transform(neighborhoods, crs = the_crs)

# Re-run plotting code (run both lines together)
# Do the neighborhoods show up now?
plot(canopy)
plot(neighborhoods_crs, add = TRUE)

# Simply run the tmap code
tm_shape(canopy) + 
    tm_raster() + 
    tm_shape(neighborhoods_crs) + 
    tm_polygons(alpha = 0.5)
```

### Dropping geometry from a data frame
One of the great innovations of sf over sp is the use of data frames for storing spatial objects. This allows you to slice and dice your spatial data in the same way you do for non-spatial data. This means you can, for example, apply dplyr verbs directly to your sf object.

One important difference between dplyr with and without spatial data is that the resulting data frames will include the geometry variable unless you explicitly drop it. If you want to force the geometry to be dropped you would use the sf function st_set_geometry() and you would set the geometry to NULL.

```{r}
 # Create a data frame of counts by species
 # Use the dplyr function count() to tally the number of trees by species from the trees dataset
species_counts <- count(trees, species, sort = TRUE)

# Use head to see if the geometry column is in the data frame
head(species_counts)

# Drop the geometry column
species_no_geometry <- st_set_geometry(species_counts, NULL)

# Confirm the geometry column has been dropped
head(species_no_geometry)
```

### Join spatial and non-spatial data
In this exercise you will test joining spatial and non-spatial data. In particular, the trees data you have been working with has a full county name (the variable is called boroname) but does not have the county codes. The neighborhoods file has both a county name (the variable is called boro_name) and the county codes -- neighborhoods are nested within counties. In this exercise, you will create a non-spatial data frame of county name and county code from the neighborhoods object. Then you will join this data frame into the spatial trees object with inner_join().

```{r}
# Limit to the fields boro_name, county_fip and boro_code
boro <- select(neighborhoods, boro_name, county_fip, boro_code)

# Drop the geometry column
boro_no_geometry <- st_set_geometry(boro, NULL)

# Limit to distinct records
# just one occurrence of each county/boro
boro_distinct <- distinct(boro_no_geometry)

# Join the county detail into the trees object
trees_with_county <- inner_join(trees, boro_distinct, by = c("boroname" = "boro_name"))

# Confirm the new fields county_fip and boro_code exist
head(trees_with_county)
```

### Simplify the neighborhood boundaries
In sf you can use the st_simplify() function to reduce line and polygon complexity. In this exercise you will measure the size of objects before and after st_simplify() in two ways. You will compute the size in megabytes using the handy object_size() function in the pryr package and you will count the number of vertices -- the number of points required to delineate a line or polygon.

```{r}
# Plot the neighborhoods geometry
plot(st_geometry(neighborhoods), col = "grey")

# Measure the size of the neighborhoods object
# count the number of vertices -- the number of points required to delineate a line or polygon
object_size(neighborhoods)

# Compute the number of vertices in the neighborhoods object
pts_neighborhoods <- st_cast(neighborhoods$geometry, "MULTIPOINT")
cnt_neighborhoods <- sapply(pts_neighborhoods, length)
sum(cnt_neighborhoods)

# Simplify the neighborhoods object
# Use the preserveTopology = TRUE argument so that borders stay aligned
# use dTolerance = 100 to set the amount of simplification allowed (this is in meters)
neighborhoods_simple <- st_simplify(neighborhoods, 
                            preserveTopology = TRUE, 
                            dTolerance = 100)

# Measure the size of the neighborhoods_simple object
object_size(neighborhoods_simple)

# Compute the number of vertices in the neighborhoods_simple object
pts_neighborhoods_simple <- st_cast(neighborhoods_simple$geometry, "MULTIPOINT")
cnt_neighborhoods_simple <- sapply(pts_neighborhoods_simple, length)
sum(cnt_neighborhoods_simple)

# Plot the neighborhoods_simple object geometry
plot(st_geometry(neighborhoods_simple), col = "grey")
```

### Converting sf objects to sp objects
In order to convert an sf object to an sp object (which has a Spatial class) you can use the as() function with Class = "Spatial". To convert back to sf you can use st_as_sf() and accept the defaults. sp objects are from the old sp package replaced by sf.

```{r}
# Read in the trees data
trees <- st_read("trees.shp")

# Convert to Spatial class
trees_sp <- as(trees, Class = "Spatial")

# Confirm conversion, should be "SpatialPointsDataFrame"
class(trees_sp)

# Convert back to sf
trees_sf <- st_as_sf(trees_sp)

# Confirm conversion
class(trees_sf)
```

### Converting to and from coordinates
In order to convert a data frame of coordinates into an sf object you can make use of the st_as_sf() function you used in the previous exercise. You can specify the coords argument with the names of the coordinate variables (with the X coordinate/longitude coordinate listed first) and, optionally, the crs argument if you know the CRS of your coordinates. The CRS can be specified as a proj4 string or EPSG code.

If you want to convert your sf point objects to a data frame with coordinates, you can use the st_write() function with a hidden argument (these are arguments associated with an external utility called GDAL and so they're not in the R help) to force sf to include the coordinates in the output file. The argument you need is layer_options = "GEOMETRY=AS_XY".

```{r}
# Read in the CSV
trees <- read.csv("trees.csv")

# Convert the data frame to an sf object
trees_sf <- st_as_sf(trees, coords = c("longitude", "latitude"), crs = 4326)

# Plot the geometry of the points
plot(st_geometry(trees_sf))

# Write the file out with coordinates
st_write(trees_sf, "new_trees.csv",  layer_options = "GEOMETRY=AS_XY", delete_dsn = TRUE)

# Read in the file you just created and check coordinates
new_trees <- read.csv("new_trees.csv")
head(new_trees)
```

### Change the raster grid cell size using aggregate
For rasters, the function to reduce resolution is aggregate() which, as you might guess, aggregates grid cells into larger grid cells using a user-defined function (for example, mean or max). The function used to aggregate the values is determined by the fun argument (the default being mean) and the amount of aggregation is driven by the fact (the default being 2) argument.

```{r}
# Read in the canopy layer
canopy <- raster("canopy.tif")

# Plot the canopy raster
plot(canopy)

# Determine the raster resolution
res(canopy)

# Determine the number of cells
ncell(canopy)

# Aggregate the raster
canopy_small <- aggregate(canopy, fact = 10)

# Plot the new canopy layer
plot(canopy_small)

# Determine the new raster resolution
res(canopy_small)

# Determine the number of cells in the new raster
ncell(canopy_small)
```

### Change values and handle missing values in rasters
There are many situations where you might need to change raster values. You may want to change outlier values to NA for example. In the raster package, reclassification is performed with the reclassify() function.

In the canopy raster you've worked with the values are percentages and are supposed to range between 0 and 100. Anything above 100 should be an NA. In this exercise you will assign any values above 100 to NA.

```{r}
# Plot the canopy layer to see the values above 100
plot(canopy)

# Set up the matrix
vals <- cbind(100, 300, NA)

# Reclassify values above 100 to NA
canopy_reclass <- reclassify(canopy, rcl = vals)

# Plot again and confirm that the legend stops at 100
plot(canopy_reclass)
```

### Buffer layers
Computing buffers is a key spatial analysis skill and the resulting buffers have a wide range of uses like, for example, identifying the number of roads within one kilometer of a school or computing the number of hazardous waste sites near sensitive natural areas.

Although, technically you can buffer data with unprojected coodinate reference systems, the buffer distance will be more meaningful with a projected CRS so it is highly recommended that you transform unprojected data to a projected CRS before buffering.

```{r}
# Review df
df

# Convert the data frame to an sf object             
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)

# Transform the points to match the manhattan CRS
df_crs <- st_transform(df_sf, crs = crs(manhattan, asText = TRUE))

# Buffer the points
df_buf <- st_buffer(df_crs, dist = 1000)

# Plot the manhattan image (it is multi-band)
plotRGB(manhattan)
plot(st_geometry(df_buf), col = "firebrick", add = TRUE)
plot(st_geometry(df_crs), pch = 16, add = TRUE)
```

### Compute polygon centroids
Similar to buffering, computing polygon centroids is a bedrock geoprocessing task used to assign values and even to help with labeling maps. The function for this in sf is st_centroid().

Also similar to buffering, centroid calculations should generally be performed on data with a projected coordinate reference system.

```{r}
# Read in the neighborhods shapefile
neighborhoods <- st_read("neighborhoods.shp")

# Project neighborhoods to match manhattan
neighborhoods_tf <- st_transform(neighborhoods, crs = 32618)

# Compute the neighborhood centroids
centroids <- st_centroid(neighborhoods_tf)

# Plot the neighborhood geometry
plot(st_geometry(neighborhoods_tf), col = "grey", border = "white")
plot(centroids, pch = 16, col = "firebrick", add = TRUE)
```

### Create a bounding box around vector data
You can compute bounding boxes around vector data using sf. These can help you, for example, create polygons to clip layers to a common area for an analysis or identify regions of influence.

In the sf package, there is a function for extracting the bounding box coordinates, if that's all you need, this is st_bbox(). More likely you'll want to create a new sf object (a polygon) from those coordinates and to do this sf provides the st_make_grid() function.

st_make_grid() can be used to make a multi-row and multi-column grid covering your input data but it can also be used to make a grid of just one cell (a bounding box). To do this, you need to specify the number of grid cells as n = 1.

```{r}
# Plot the neighborhoods and beech trees
plot(st_geometry(neighborhoods), col = "grey", border = "white")
plot(beech, add = TRUE, pch = 16, col = "forestgreen")

# Compute the coordinates of the bounding box
st_bbox(beech)

# Create a bounding box polygon
beech_box <- st_make_grid(beech, n = 1)

# Plot the neighborhoods, add the beech trees and add the new box
plot(st_geometry(neighborhoods), col = "grey", border = "white")
plot(beech, add = TRUE, pch = 16, col = "forestgreen")
plot(beech_box, add = TRUE)
```

### Dissolve multiple features into one
In order to compute a tighter bounding box, a convex hull, around a set of points like the beech trees from the previous exercise you'll need to learn one more function first.

For points you don't want a convex hull around each point! This doesn't even make sense. More likely you want to compute a convex hull around all your points. If you have a set of points and you want to draw a convex hull around them you first need to bundle the points into a single MULTIPOINT feature and in order to do this you will use the dissolve function in sf called st_union().

With polygons, st_union() will dissolve all the polygons into a single polygon representing the area where all the polygons overlap. Your set of individual points will be dissolved/unioned into a single, MULTIPOINT feature that you can use for tasks like computing the convex hull.

```{r}
# Buffer the beech trees by 3000
beech_buffer <- st_buffer(beech, dist=3000)

# Limit the object to just geometry
beech_buffers <- st_geometry(beech_buffer)

# Compute the number of features in beech_buffer
length(beech_buffers)

# Plot the tree buffers
plot(beech_buffers)

# Dissolve the buffers
beech_buf_union <- st_union(beech_buffers)

# Compute the number of features in beech_buf_union
length(beech_buf_union)

# Plot the dissolved buffers
plot(beech_buf_union)
```

### Compute a convex hull around vectors
A more precise bounding polygon is sometimes needed, one that fits your data more neatly. For this, you can use the st_convex_hull() function. Note that st_convex_hull() will compute a tight box around each one of your features individually so if you want to create a convex hull around a group of features you'll need to use st_union() to combine individual features into a single multi-feature.

```{r}
# Look at the data frame to see the type of geometry
head(beech)

# Convert the points to a single multi-point
beech1 <- st_union(beech)

# Look at the data frame to see the type of geometry
head(beech1)

# Confirm that we went from 17 features to 1 feature
length(beech)
length(beech1)

# Compute the tight bounding box
beech_hull <- st_convex_hull(beech1)

# Plot the points together with the hull
plot(beech_hull, col = "red")
plot(beech1, add = TRUE)
```

### Spatial joins
For many analysis types you need to link geographies spatially. For example, you want to know how many trees are in each neighborhood but you don't have a neighborhood attribute in the tree data. The best way to do this is with a spatial join using st_join().

Importantly, the st_join() function requires sf data frames as input and will not accept an object that is just sf geometry. You can use the st_sf() function to convert sf geometry objects to an sf data frame (st_sf() is essentially the opposite of st_geometry()).

```{r}
# Plot the beech on top of the neighborhoods
plot(st_geometry(neighborhoods))
plot(beech, add = TRUE, pch = 16, col = "red")

# Determine whether beech has class data.frame
class(beech)

# Convert the beech geometry to a sf data frame
beech_df <- st_sf(beech)

# Confirm that beech now has the data.frame class
class(beech_df)

# Join the beech trees with the neighborhoods
beech_neigh <- st_join(beech_df, neighborhoods)

# Confirm that beech_neigh has the neighborhood information
head(beech_neigh)
```

### Spatial relationships
In this exercise you will determine which neighborhoods are at least partly within 2000 meters of the Empire State Building with st_intersects() and those that are completely within 2000 meters of the Empire State Building using st_contains(). You will then use the st_intersection() function (notice the slight difference in function name!) to clip the neighborhoods to the buffer.

A note about the output of functions that test relationships between two sets of features. The output of these and related functions is a special kind of list (with the class sgbp). For example, when using st_intersects(), the first element in the output can be accessed using [[1]], which shows polygons from the second polygon that intersect with the first polygon. Likewise, [[2]] would show the polygons from from the first polygon that intersect with the second polygon.

```{r}
# Identify neighborhoods that intersect with the buffer
neighborhoods_int <- st_intersects(buf, neighborhoods)

# Identify neighborhoods contained by the buffer
neighborhoods_cont <- st_contains(buf, neighborhoods)

# Get the indexes of which neighborhoods intersect
# and are contained by the buffer
int <- neighborhoods_int[[1]]
cont <- neighborhoods_cont[[1]]

# Get the names of the names of neighborhoods in buffer
neighborhoods$ntaname[int]

# Clip the neighborhood layer by the buffer (ignore the warning)
neighborhoods_clip <- st_intersection(buf, neighborhoods)

# Plot the geometry of the clipped neighborhoods
plot(st_geometry(neighborhoods_clip), col = "red")
plot(neighborhoods[cont,], add = TRUE, col = "yellow")
```

### Measuring distance between features
Of course, measuring distance between feature sets is a component of spatial analysis 101 -- a core skill for any analyst. There are several functions in base R as well as in the packages rgeos and geosphere to compute distances, but the st_distance() function from sf provides a useful feature-to-feature distance matrix as output and can be used for most distance calculation needs.

In this exercise you'll measure the distance from the Empire State Building to all the parks and identify the closest one.

```{r}
# Read in the parks object
parks <- st_read("parks.shp")

# Test whether the CRS match
st_crs(empire_state) == st_crs(parks)

# Project parks to match empire state
parks_es <- st_transform(parks, crs = st_crs(empire_state))

# Compute the distance between empire_state and parks_es
d <- st_distance(empire_state, parks_es)

# Take a quick look at the result
head(d)

# Find the index of the nearest park
nearest <- which.min(d)

# Identify the park that is nearest
parks_es[nearest, ]
```

### Limit rasters to focus areas
Mask and crop are similar operations that allow you to limit your raster to a specific area of interest. With mask() you essentially place your area of interest on top of the raster and any raster cells outside of the boundary are assigned NA values. A reminder that currently the raster package does not support sf objects so they will need to be converted to Spatial objects with, for example, as(input, "Spatial")

```{r}
# Project parks to match canopy
parks_cp <- st_transform(parks, crs = crs(canopy, asText = TRUE))

# Compute the area of the parks
areas <- st_area(parks_cp)

# Filter to parks with areas > 30000
parks_big <- filter(parks_cp, unclass(areas) > 30000)

# Plot the canopy raster
plot(canopy)

# Plot the geometry of parks_big
plot(st_geometry(parks_big))

# Convert parks to a Spatial object
parks_sp <- as(parks_big, "Spatial")

# Mask the canopy layer with parks_sp and save as canopy_mask
canopy_mask <- mask(canopy, mask = parks_sp)

# Plot canopy_mask -- this is a raster!
plot(canopy_mask)
```

### Crop a raster based on another spatial object
As you saw in the previous exercise with mask(), the raster extent is not changed. If the extents of the input raster and the mask itself are different then they will still be different after running mask(). In many cases, however, you will want your raster to share an extent with another layer and this is where crop() comes in handy. With crop() you are cropping the raster so that the extent (the bounding box) of the raster matches the extent of the input crop layer. But within the bounding box no masking is done (no raster cells are set to NA).

In this exercise you will both mask and crop the NYC canopy layer based on the large parks and you'll compare. You should notice that the masked raster includes a lot of NA values (there are the whitespace) and that the extent is the same as the original canopy layer. With the cropped layer you should notice that the extent of the cropped canopy layer matches the extent of the large parks (essentially it's zoomed in).

```{r}
# Convert the parks_big to a Spatial object
parks_sp <- as(parks_big, "Spatial")

# Mask the canopy with the large parks 
canopy_mask <- mask(canopy, mask = parks_sp)

# Plot the mask
plot(canopy_mask)

# Crop canopy with parks_sp
canopy_crop <- crop(canopy, parks_sp)

# Plot the cropped version and compare
plot(canopy_crop)
```

### Extract raster values by location
Beyond simply masking and cropping you may want to know the actual cell values at locations of interest. You might, for example, want to know the percentage canopy at your landmarks or within the large parks. This is where the extract() function comes in handy.

Usefully, and you'll see this in a later analysis, you can feed extract() a function that will get applied to extracted cells. For example, you can use extract() to extract raster values by neighborhood and with the fun = mean argument it will return an average cell value by neighborhood.

Similar to other raster functions, it is not yet set up to accept sf objects so you'll need to convert to a Spatial object.

```{r}
# Project the landmarks to match canopy
landmarks_cp <- st_transform(landmarks, crs = crs(canopy, asText = TRUE))

# Convert the landmarks to a Spatial object
landmarks_sp <- as(landmarks_cp, "Spatial")

# Extract the canopy values at the landmarks
landmarks_ex <- extract(canopy, landmarks_sp)

# Look at the landmarks and extraction results
landmarks_cp
landmarks_ex
```

### Raster math with overlay
You will now use the canopy layer and an "imperviousness" layer from the same source, the United States Geological Survey. Imperviousness measures whether water can pass through a surface. So a high percentage impervious surface might be a road that does not let water pass through while a low percentage impervious might be something like a lawn.

What you will do in this exercise is essentially identify the most urban locations by finding areas that have both a low percentage of tree canopy ([removed] 80%). To do this, we defined the function f to do the raster math for you.

```{r}
# Read in the canopy and impervious layer
canopy <- raster("canopy.tif")
impervious <- raster("impervious.tif")

# Function f with 2 arguments and the raster math code
f <- function(rast1, rast2) {
  rast1 < 20 & rast2 > 80
}

# Do the overlay using f as fun
canopy_imperv_overlay <- overlay(canopy, impervious, fun = f)

# Plot the result (low tree canopy and high impervious areas)
plot(canopy_imperv_overlay)
```

### Compute tree density by neighborhood (I)
In order to compute tree density by neighborhood you need two things. You will need to know the area of the neighborhoods, which you will compute in the next exercise. And you need the tree counts by neighborhood which is the focus of this exercise.

You will produce counts of all trees by neighborhood in NYC and create a single data frame with a column for total trees. The result should be a data frame with no geometry.

```{r}
# Compute the counts of all trees by hood
tree_counts <- count(trees, hood)

# Take a quick look
head(tree_counts)

# Remove the geometry
tree_counts_no_geom <- st_set_geometry(tree_counts, NULL)

# Rename the n variable to tree_cnt
tree_counts_renamed <- rename(tree_counts_no_geom, tree_cnt = n)
  
# Create histograms of the total counts
hist(tree_counts_renamed$tree_cnt)
```

### Compute tree density by neighborhood (II)
We have the tree counts (from the previous exercise). In this exercise you will compute neighborhood areas, add them to the neighborhood sf object and then you'll join in the non-spatial tree counts data frame from the previous exercise.

```{r}
# Compute areas and unclass to remove units
areas <- unclass(st_area(neighborhoods))

# Add the areas to the neighborhoods object
neighborhoods_area <- mutate(neighborhoods, area = areas)

# Join neighborhoods and counts
neighborhoods_counts <- left_join(neighborhoods_area, 
                            tree_counts_renamed, by = "hood")

# Replace NA values with 0
neighborhoods_counts <- mutate(neighborhoods_counts, 
                            tree_cnt = ifelse(is.na(tree_cnt), 
                                              0, tree_cnt))

# Compute the density
neighborhoods_counts <- mutate(neighborhoods_counts, 
                               tree_density = tree_cnt/area)
```

### Compute average tree canopy by neighborhood
In the previous exercises you computed tree density by neighborhood using tree counts. In this exercise you will compute average tree canopy by neighborhood as a percentage so that we can compare if the results are similar.

```{r}
# Confirm that you have the neighborhood density results
head(neighborhoods)

# Transform the neighborhoods CRS to match the canopy layer
neighborhoods_crs <- st_transform(neighborhoods, crs = st_crs(canopy, asText = TRUE))

# Convert neighborhoods object to a Spatial object
neighborhoods_sp <- as(neighborhoods_crs, Class = "Spatial")

# Compute the mean of canopy values by neighborhood
canopy_neighborhoods <- extract(canopy, neighborhoods_sp, fun = mean)

# Add the mean canopy values to neighborhoods
neighborhoods_avg_canopy <- mutate(neighborhoods, avg_canopy = canopy_neighborhoods)
```

### Create plots using ggplot2
As an initial review of the data you created you will compute correlations and create histograms and a scatter plot using ggplot2.

```{r}
# Load the ggplot2 package
library(ggplot2)

# Create a histogram of tree density (tree_density)
ggplot(neighborhoods, aes(x = tree_density)) + 
  geom_histogram(color = "white")

# Create a histogram of average canopy (avg_canopy)
ggplot(neighborhoods, aes(x = avg_canopy)) + 
  geom_histogram(color = "white")

# Create a scatter plot of tree_density vs avg_canopy
ggplot(neighborhoods, aes(x = tree_density, y = avg_canopy)) + 
    geom_point() + 
    stat_smooth()

# Compute the correlation between density and canopy
cor(neighborhoods$tree_density, neighborhoods$avg_canopy)
```

### Create a map using ggplot2
The geom_sf() function operates like any other layer in ggplot2 where you can link variables to aesthetics on the plot through the aes() function. In a mapping context this might mean, for example, creating a choropleth map by color coding the polygons based on a variable. If you leave off the aesthetic mapping geom_sf() will map the geometry alone.

```{r}
# Plot the tree density with default colors
ggplot(neighborhoods) + 
  geom_sf(aes(fill = tree_density))

# Plot the tree canopy with default colors
ggplot(neighborhoods) + 
  geom_sf(aes(fill = avg_canopy))
  
# Plot the tree density using scale_fill_gradient()
ggplot(neighborhoods) + 
  geom_sf(aes(fill = tree_density)) + 
  scale_fill_gradient(low = "#edf8e9", high = "#005a32")

# Plot the tree canopy using the scale_fill_gradient()
ggplot(neighborhoods) + 
  geom_sf(aes(fill = avg_canopy)) +
  scale_fill_gradient(low = "#edf8e9", high = "#005a32")
```

### Create a map using tmap
The tmap package is an excellent tool for making maps. You'll see that it simplifies the process of binning your data values for nice maps and makes it easy to stitch together different layers.

tmap operates similarly to ggplot2 in the sense that it starts with a function, in this case tm_shape(), to set up the map and then is followed by layers and other instructions separated with the +.

```{r}
# Create a simple map of neighborhoods
tm_shape(neighborhoods) + 
    tm_polygons()

# Create a color-coded map of neighborhood tree density
tm_shape(neighborhoods) + 
    tm_polygons("tree_density")

# Style the tree density map
tm_shape(neighborhoods) + 
    tm_polygons("tree_density", palette = "Greens", 
                style = "quantile", n = 7, 
                title = "Trees per sq. KM")

# Create a similar map of average tree canopy
tm_shape(neighborhoods) + 
    tm_polygons("avg_canopy", palette = "Greens", 
                style = "quantile", n = 7, 
                title = "Average tree canopy (%)")
```

### Use tmap to create a final pretty map
In this exercise you will use tmap to create a final map with three map views to help you to compare the green you see in an aerial photo with the tree density and average canopy results you computed by neighborhood. The question you're trying to answer is which measure, tree density or average tree canopy, more closely matches what you can see in the aerial photo.

Note: In map2, you will make use of the bbox argument to force the view extents to match the aerial photo.

```{r}
# Create a map of the manhattan aerial photo
tm_shape(manhattan) + 
  tm_raster()

# Create a map of the neighborhood polygons
tm_shape(neighborhoods) + 
  tm_borders(col = "black", lwd = 0.5, alpha = 0.5)

# Combine the aerial photo and neighborhoods into one map
map1 <- tm_shape(manhattan) + 
  tm_raster() + 
  tm_shape(neighborhoods) + 
  tm_borders(col = "black", lwd = 0.5, alpha = 0.5)

# Create the second map of tree measures
map2 <- tm_shape(neighborhoods, bbox = bbox(manhattan)) +
  tm_polygons(
    c("tree_density", "avg_canopy"), 
    style = "quantile",
    palette = "Greens",
    title = c("Tree Density", "Average Tree Canopy")) 

# Combine the two maps into one
tmap_arrange(map1, map2, asp = NA)
```


