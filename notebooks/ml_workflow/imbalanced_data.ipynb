{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "\n",
    "Can You Collect More Data?\n",
    "\n",
    "Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).\n",
    "Precision: A measure of a classifiers exactness.\n",
    "Recall: A measure of a classifiers completeness\n",
    "F1 Score (or F-score): A weighted average of precision and recall.\n",
    "I would also advice you to take a look at the following:\n",
    "\n",
    "Kappa (or Cohen’s kappa): Classification accuracy normalized by the imbalance of the classes in the data.\n",
    "ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.\n",
    "\n",
    "Try Resampling Your Dataset\n",
    "\n",
    "Consider testing under-sampling when you have an a lot data (tens- or hundreds of thousands of instances or more)\n",
    "Consider testing over-sampling when you don’t have a lot of data (tens of thousands of records or less)\n",
    "Consider testing random and non-random (e.g. stratified) sampling schemes.\n",
    "Consider testing different resampled ratios (e.g. you don’t have to target a 1:1 ratio in a binary classification problem, try other ratios)\n",
    "\n",
    "Try Generate Synthetic Samples\n",
    "\n",
    "\n",
    "Try Different Algorithms\n",
    "\n",
    "As always, I strongly advice you to not use your favorite algorithm on every problem. You should at least be spot-checking a variety of different types of algorithms on a given problem.\n",
    "\n",
    "For more on spot-checking algorithms, see my post “Why you should be Spot-Checking Algorithms on your Machine Learning Problems”.\n",
    "\n",
    "That being said, decision trees often perform well on imbalanced datasets. The splitting rules that look at the class variable used in the creation of the trees, can force both classes to be addressed.\n",
    "\n",
    "If in doubt, try a few popular decision tree algorithms like C4.5, C5.0, CART, and Random Forest.\n",
    "\n",
    "For some example R code using decision trees, see my post titled “Non-Linear Classification in R with Decision Trees“.\n",
    "\n",
    "For an example of using CART in Python and scikit-learn, see my post titled “Get Your Hands Dirty With Scikit-Learn Now“.\n",
    "\n",
    "Try Penalized Models\n",
    "\n",
    "You can use the same algorithms but give them a different perspective on the problem.\n",
    "\n",
    "Penalized classification imposes an additional cost on the model for making classification mistakes on the minority class during training. These penalties can bias the model to pay more attention to the minority class.\n",
    "\n",
    "Often the handling of class penalties or weights are specialized to the learning algorithm. There are penalized versions of algorithms such as penalized-SVM and penalized-LDA.\n",
    "\n",
    "It is also possible to have generic frameworks for penalized models. For example, Weka has a CostSensitiveClassifier that can wrap any classifier and apply a custom penalty matrix for miss classification.\n",
    "\n",
    "Using penalization is desirable if you are locked into a specific algorithm and are unable to resample or you’re getting poor results. It provides yet another way to “balance” the classes. Setting up the penalty matrix can be complex. You will very likely have to try a variety of penalty schemes and see what works best for your problem.\n",
    "\n",
    "Try a Different Perspective\n",
    "\n",
    "There are fields of study dedicated to imbalanced datasets. They have their own algorithms, measures and terminology.\n",
    "\n",
    "Taking a look and thinking about your problem from these perspectives can sometimes shame loose some ideas.\n",
    "\n",
    "Two you might like to consider are anomaly detection and change detection.\n",
    "\n",
    "Anomaly detection is the detection of rare events. This might be a machine malfunction indicated through its vibrations or a malicious activity by a program indicated by it’s sequence of system calls. The events are rare and when compared to normal operation.\n",
    "\n",
    "This shift in thinking considers the minor class as the outliers class which might help you think of new ways to separate and classify samples.\n",
    "\n",
    "Change detection is similar to anomaly detection except rather than looking for an anomaly it is looking for a change or difference. This might be a change in behavior of a user as observed by usage patterns or bank transactions.\n",
    "\n",
    "Both of these shifts take a more real-time stance to the classification problem that might give you some new ways of thinking about your problem and maybe some more techniques to try.\n",
    "\n",
    "Try Getting Creative\n",
    "\n",
    "Really climb inside your problem and think about how to break it down into smaller problems that are more tractable.\n",
    "\n",
    "For inspiration, take a look at the very creative answers on Quora in response to the question “In classification, how do you handle an unbalanced training set?”\n",
    "\n",
    "For example:\n",
    "\n",
    "Decompose your larger class into smaller number of other classes…\n",
    "\n",
    "…use a One Class Classifier… (e.g. treat like outlier detection)\n",
    "\n",
    "…resampling the unbalanced training set into not one balanced set, but several. Running an ensemble of classifiers on these sets could produce a much better result than one classifier alone\n",
    "\n",
    "These are just a few of some interesting and creative ideas you could try.\n",
    "\n",
    "For more ideas, check out these comments on the reddit post “Classification when 80% of my training set is of one class“.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalanced Classification\n",
    "\n",
    "one class outnumbers other class by a large proportion\n",
    "\n",
    "Undersampling: majority class\n",
    "\n",
    "Random undersampling method randomly chooses observations from majority class which are eliminated until the data set gets balanced. Informative undersampling follows a pre-specified selection criterion to remove the observations from majority class.\n",
    "\n",
    "Within informative undersampling, EasyEnsemble and BalanceCascade algorithms are known to produce good results. These algorithms are easy to understand and straightforward too.\n",
    "\n",
    "\n",
    "\n",
    "Oversampling: minority class\n",
    "\n",
    "Random Oversampling and Informative Oversampling.\n",
    "\n",
    "Synthetic Data Generation: generates artificial data. It is also a type of oversampling technique.\n",
    "synthetic minority oversampling technique (SMOTE) is a powerful and widely used method. SMOTE algorithm creates artificial data based on feature space (rather than data space) similarities from minority samples. We can also say, it generates a random set of minority class observations to shift the classifier learning bias towards minority class.\n",
    "\n",
    "\n",
    "Cost Sensitive Learning\n",
    "\n",
    "Cost Matrix is similar of confusion matrix. It’s just, we are here more concerned about false positives and false negatives (shown below). There is no cost penalty associated with True Positive and True Negatives as they are correctly identified.\n",
    "\n",
    "There are other advanced methods as well for balancing imbalanced data sets. These are Cluster based sampling, adaptive synthetic sampling, border line SMOTE, SMOTEboost, DataBoost – IM, kernel based methods and many more. The basic working on these algorithm is almost similar as explained above. There are more intuitive methods which you can try for improved predictions:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
