{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorech Python Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros([2,5])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5418, 0.3419, 0.8671, 0.1539, 0.5108],\n",
       "        [0.4349, 0.3990, 0.8015, 0.1937, 0.6169]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5418, 0.3419, 0.8671, 0.1539, 0.5108, 0.4349, 0.3990, 0.8015, 0.1937,\n",
       "         0.6169]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5418, 0.3419, 0.8671, 0.1539, 0.5108, 0.4349, 0.3990, 0.8015, 0.1937,\n",
       "         0.6169]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape([1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a68eabd599f4866b31f7c5d05ddff07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\Jack\\Desktop\\MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15fb4c7cc1d4dc484da89ae3beb9e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\Jack\\Desktop\\MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4078794c7e453a889478cd082fd2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\Jack\\Desktop\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8283c55b40304f9db0c600e6aebe1f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\Jack\\Desktop\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\Jack\\Desktop\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\Jack\\Desktop'\n",
    "\n",
    "train = datasets.MNIST(file_path, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST(file_path, train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 7, 3, 6, 0, 9, 5, 8, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    # 10 tensors of the images\n",
    "    # then a tensor of 10 classifications\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.2039, 0.7569, 0.3373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.7294, 0.9961, 0.9765, 0.4549, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0706, 0.4588, 0.9961, 0.9686, 0.7490, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0863, 0.7412, 0.9961, 0.9725, 0.3294,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.8157, 0.9961, 0.8000,\n",
       "           0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118, 1.0000, 0.9961,\n",
       "           0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n",
       "           0.7608, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4196, 0.9961,\n",
       "           0.9961, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1098, 0.9961,\n",
       "           0.9961, 0.7333, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824, 0.8824,\n",
       "           0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
       "           0.9961, 0.9961, 0.5255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
       "           0.9961, 0.9961, 0.8863, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "           0.7059, 0.9961, 0.8118, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.4902, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
       "           0.9725, 0.9961, 0.8039, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078,\n",
       "           0.9961, 0.9961, 0.8902, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3686, 0.7843, 0.7843,\n",
       "           0.7843, 0.7843, 0.5490, 0.2471, 0.2471, 0.2471, 0.3059, 0.9059,\n",
       "           0.9961, 0.9961, 0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9961, 0.9961,\n",
       "           0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
       "           0.9961, 0.9961, 0.7412, 0.2392, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.8039, 0.9961,\n",
       "           0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
       "           0.9961, 0.9961, 0.9961, 0.8863, 0.1608, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020, 0.8235,\n",
       "           0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9843,\n",
       "           0.4588, 0.4588, 0.4588, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]), tensor(2))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28bb63a5470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # fc: fully connected\n",
    "        #input 784 = 28*28 flattened image\n",
    "        # output hidden layer = 64\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    # x is the data\n",
    "    # defines how data flows through the network\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out network with random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2656, -2.3743, -2.4249, -2.2125, -2.3583, -2.3294, -2.3315, -2.3896,\n",
       "         -2.1530, -2.2222]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3953, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0775, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.972\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADT1JREFUeJzt3X+s3fVdx/HXq5fblhbQ1tKuKVV+FYRg6JqboqKmphbZMleIW7P+YaqZXExGwpKpw8YEEl1CjAzJ1MWLrStxdJBs2Jqggp0RF6FyITjKOjfAwkqvvWDHKDD78+0f91u9lHu+5/ac7/d8z+37+UjIOef7/p7zeeeU1/2ecz7fcz6OCAHIZ1bTDQBoBuEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5DUOb0cbLbnxFzN7+WQQCr/o3d0NI54Ovt2FX7bN0q6T9KApL+MiLvL9p+r+brOa7sZEkCJ3bFr2vt2/LLf9oCkP5P0IUlXS9po++pOHw9Ab3Xznn+1pBcj4uWIOCrpK5LWV9MWgLp1E/5lkr436fb+Ytt72B62PWp79JiOdDEcgCp1E/6pPlR43/eDI2IkIoYiYmhQc7oYDkCVugn/fknLJ92+SNKB7toB0CvdhP9pSStsX2J7tqRPSNpZTVsA6tbxVF9EHLd9m6R/0MRU39aIeKGyzgDUqqt5/oh4VNKjFfUCoIc4vRdIivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkulql1/Y+SYclnZB0PCKGqmgKQP26Cn/hFyPijQoeB0AP8bIfSKrb8Iekx2w/Y3u4ioYA9Ea3L/uvj4gDthdLetz2tyPiick7FH8UhiVpruZ1ORyAqnR15I+IA8XluKRHJK2eYp+RiBiKiKFBzelmOAAV6jj8tufbPv/UdUk3SNpTVWMA6tXNy/4lkh6xfepxHoyIv6+kKwC16zj8EfGypGsr7AUNGLjy8tL6d25ZVFo/eeHR0vrL67aecU+nvHTs7dL68G/cXlo/5+vPdDx2Bkz1AUkRfiApwg8kRfiBpAg/kBThB5JyRPRssAu8MK7z2p6NV6UTa1a1rM3+9/8sve8rv3VVaf3Y+d39G/zhxx5sWVt37ljpfWdNnKfR0jzP7qinXnjyyEBp/XOXruxRJ/1jd+zSW3Go/B+1wJEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Kq4td7U/i9Ldta1lYM/qD0vksGHiutz6r1b/DZ++tJd760vrQ+W6/0qJOZiSM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFPP803fPqL7es7bjib3vYSW99+Ns3ldYPvXtuaf2pVdurbOc9xr++rLR+EfP8pTjyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSbef5bW+V9BFJ4xFxTbFtoaSHJF0saZ+kDRHx/fra7AM3v9OydNPCXy2967c+e2Fpfe7YYGn90gcOlNbrdM5/jZfWF666ovwBHqqwGVRqOkf+L0m68bRtd0jaFRErJO0qbgOYQdqGPyKekHTotM3rJZ36aZttkspPAwPQdzp9z78kIsYkqbhcXF1LAHqh9nP7bQ9LGpakuZpX93AApqnTI/9B20slqbhs+alQRIxExFBEDA2exT8mCcw0nYZ/p6RNxfVNknZU0w6AXmkbftvbJT0p6Urb+21/UtLdktbZ/q6kdcVtADNI2/f8EbGxRWltxb30tRNvlvw2f1lN0hW37utq7ONd3bter6/ic5yZijP8gKQIP5AU4QeSIvxAUoQfSIrwA0nx093oyoJfea22xz544oel9R996WRtY2fAkR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKeH6XiZ68trf/FFX/e5hHmdjz2nqM/Vlo/7+GnOn5scOQH0iL8QFKEH0iK8ANJEX4gKcIPJEX4gaSY50epV26P0vol53Q+j9/OX4//TJs93qxt7Aw48gNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUm3n+W1vlfQRSeMRcU2x7S5Jt0h6vdhtc0Q8WleTqM/AksWl9Y+ueL62sd9o87v8L33hJ0vrF4jv83djOkf+L0m6cYrt90bEyuI/gg/MMG3DHxFPSDrUg14A9FA37/lvs/1N21ttL6isIwA90Wn4vyjpMkkrJY1JuqfVjraHbY/aHj2mIx0OB6BqHYU/Ig5GxImIOCnpfkmrS/YdiYihiBga1JxO+wRQsY7Cb3vppJs3S9pTTTsAemU6U33bJa2RtMj2fkl3Slpje6WkkLRP0q019gigBm3DHxEbp9i8pYZe0ICxj11eWt+x5O9qG/vnH/qd0vpl25+sbWxwhh+QFuEHkiL8QFKEH0iK8ANJEX4gKX66+yw3sKh8mesbfvNfax2/7Gu7Fz5b/rPgqBdHfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iinn+s9zYhitL6zsWf6Grx2/389tr7//dlrXl2+s9xwDlOPIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFLM858FBha0Xirxo7f+c61jb3lzqLS+/A+Yy+9XHPmBpAg/kBThB5Ii/EBShB9IivADSRF+IKm28/y2l0t6QNIHJJ2UNBIR99leKOkhSRdL2idpQ0R8v75W0crYxqta1n5/0T/2sBPMJNM58h+X9JmIuErST0v6lO2rJd0haVdErJC0q7gNYIZoG/6IGIuIZ4vrhyXtlbRM0npJ24rdtkm6qa4mAVTvjN7z275Y0gcl7Za0JCLGpIk/EJIWV90cgPpMO/y2z5P0VUmfjoi3zuB+w7ZHbY8e05FOegRQg2mF3/agJoL/5Yj4WrH5oO2lRX2ppPGp7hsRIxExFBFDg5pTRc8AKtA2/LYtaYukvRHx+UmlnZI2Fdc3SdpRfXsA6jKdr/ReL+nXJD1v+7li22ZJd0t62PYnJb0q6eP1tIh2brilua/N/tWuNaX1y/VUbxrBGWsb/oj4hiS3KK+tth0AvcIZfkBShB9IivADSRF+ICnCDyRF+IGk+OnuGWDWvHml9Xmz3qxt7HfjaGl98b/VNjRqxpEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Jinn8G+O8N15bWNy/609rG/u3Xfqm0fsF2vq8/U3HkB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkmOdHqRfu/anS+vn8Lv+MxZEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JqO89ve7mkByR9QNJJSSMRcZ/tuyTdIun1YtfNEfFoXY1mtnDP4dL6rh+2/l3/tee+W3rfne8sKK3/yN4flNZPllbRz6Zzks9xSZ+JiGdtny/pGduPF7V7I+KP62sPQF3ahj8ixiSNFdcP294raVndjQGo1xm957d9saQPStpdbLrN9jdtb7U95etH28O2R22PHtORrpoFUJ1ph9/2eZK+KunTEfGWpC9KukzSSk28MrhnqvtFxEhEDEXE0KDmVNAygCpMK/y2BzUR/C9HxNckKSIORsSJiDgp6X5Jq+trE0DV2obftiVtkbQ3Ij4/afvSSbvdLGlP9e0BqIsjonwH++ck/Yuk5/X/MzubJW3UxEv+kLRP0q3Fh4MtXeCFcZ3XdtkygFZ2xy69FYc8nX2n82n/NyRN9WDM6QMzGGf4AUkRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmr7ff5KB7Nfl/TKpE2LJL3RswbOTL/21q99SfTWqSp7+4mIuHA6O/Y0/O8b3B6NiKHGGijRr731a18SvXWqqd542Q8kRfiBpJoO/0jD45fp1976tS+J3jrVSG+NvucH0Jymj/wAGtJI+G3faPs/bL9o+44memjF9j7bz9t+zvZow71stT1ue8+kbQttP277u8Vl+TK7ve3tLtuvFc/dc7Y/3FBvy23/k+29tl+wfXuxvdHnrqSvRp63nr/stz0g6TuS1knaL+lpSRsj4ls9baQF2/skDUVE43PCtn9B0tuSHoiIa4ptfyTpUETcXfzhXBARn+2T3u6S9HbTKzcXC8osnbyytKSbJP26GnzuSvraoAaetyaO/KslvRgRL0fEUUlfkbS+gT76XkQ8IenQaZvXS9pWXN+mif95eq5Fb30hIsYi4tni+mFJp1aWbvS5K+mrEU2Ef5mk7026vV/9teR3SHrM9jO2h5tuZgpLTq2MVFwubrif07VdubmXTltZum+eu05WvK5aE+GfavWffppyuD4iVkn6kKRPFS9vMT3TWrm5V6ZYWbovdLriddWaCP9+Scsn3b5I0oEG+phSRBwoLsclPaL+W3344KlFUovL8Yb7+T/9tHLzVCtLqw+eu35a8bqJ8D8taYXtS2zPlvQJSTsb6ON9bM8vPoiR7fmSblD/rT68U9Km4vomSTsa7OU9+mXl5lYrS6vh567fVrxu5CSfYirjTyQNSNoaEZ/reRNTsH2pJo720sQipg822Zvt7ZLWaOJbXwcl3SnpbyQ9LOnHJb0q6eMR0fMP3lr0tkZnuHJzTb21Wll6txp87qpc8bqSfjjDD8iJM/yApAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyT1vwddr+nZGrirAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\na_featureset = X[0]\\nreshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\\noutput = net(reshaped_for_network) #output will be a list of network predictions.\\nfirst_pred = output[0]\\nprint(first_pred)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "# broken down in more detail\n",
    "'''\n",
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cats vs dogs classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-aaba25dcadb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy way to create hot encoded arrays:\n",
    "np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = r\"C:\\Users\\Jack\\Desktop\\PetImages\\Cat\"\n",
    "    DOGS = r\"C:\\Users\\Jack\\Desktop\\PetImages\\Dog\"\n",
    "    TESTING = r\"C:\\Users\\Jack\\Desktop\\PetImages\\Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(r\"C:\\Users\\Jack\\Desktop\\PetImages\\training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(r\"C:\\Users\\Jack\\Desktop\\PetImages\\training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0])\n",
    "\n",
    "plt.imshow(X[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda_is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda_is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "# or when creating an instance of net - net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "def train(net):\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 3\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in range(0, len(train_X), BATCH_SIZE): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "            #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            net.zero_grad()\n",
    "\n",
    "            optimizer.zero_grad()   # zero the gradient buffers\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.to(device)\n",
    "test_y.to(device)\n",
    "\n",
    "def test(net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            real_class = torch.argmax(test_y[i]).to(device)\n",
    "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]  # returns a list, \n",
    "            predicted_class = torch.argmax(net_out)\n",
    "\n",
    "            if predicted_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    print(\"Accuracy: \", round(correct/total, 3))\n",
    "\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in tqdm(range(0, len(test_X), BATCH_SIZE)):\n",
    "\n",
    "    batch_X = test_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)\n",
    "    batch_y = test_y[i:i+BATCH_SIZE].to(device)\n",
    "    batch_out = net(batch_X)\n",
    "\n",
    "    out_maxes = [torch.argmax(i) for i in batch_out]\n",
    "    target_maxes = [torch.argmax(i) for i in batch_y]\n",
    "    for i,j in zip(out_maxes, target_maxes):\n",
    "        if i == j:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
